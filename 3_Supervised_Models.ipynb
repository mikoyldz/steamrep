{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Methoden: Random Forest und Logistische Regression mit Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook schauen wir uns zwei supervised learning Methoden an, Random Forest und die Logistische Regression. Wir werden es in diesem Notebook sehr einfach halten, da das Hauptaugenmerk auf DistilBert und seinen Variationen liegt.\n",
    "\n",
    "Wir wollen lediglich schauen, wie gut denn eine \"klasschische\" supervised learning Methode sich im Vergleich zum Transformer macht und sich die geringe Trainingszeit lohnt.\n",
    "\n",
    "Das Dataset ist aus **1_Emotion_Model.ipynb** und behinhalet schon alle Emotionsvektoren sowie die Spalte *cleaned_review*. Für die Word2Vec Modelle werden wir aber noch die Punktutations, special Charaktere und Zahlen weggeben und eine neue Spalte *cleaned_review_sv* anheften."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/processed_data/steam_reviews_with_emotions_full.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_id</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>timestamp_created</th>\n",
       "      <th>timestamp_updated</th>\n",
       "      <th>recommended</th>\n",
       "      <th>votes_helpful</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620980</td>\n",
       "      <td>Beat Saber</td>\n",
       "      <td>79244667</td>\n",
       "      <td>english</td>\n",
       "      <td>Since I am 80 + years old, it is very importan...</td>\n",
       "      <td>2020-11-14 10:51:22</td>\n",
       "      <td>2020-11-14 10:51:22</td>\n",
       "      <td>True</td>\n",
       "      <td>1493</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.094612</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.349538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1113000</td>\n",
       "      <td>Persona 4 Golden</td>\n",
       "      <td>70806847</td>\n",
       "      <td>english</td>\n",
       "      <td>Please buy this game if you want more Persona ...</td>\n",
       "      <td>2020-06-15 02:03:47</td>\n",
       "      <td>2020-11-26 04:15:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1490</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1145360</td>\n",
       "      <td>Hades</td>\n",
       "      <td>75662801</td>\n",
       "      <td>english</td>\n",
       "      <td>You can date the medusa head.\n",
       "\n",
       "Post Launch Edi...</td>\n",
       "      <td>2020-09-08 19:18:50</td>\n",
       "      <td>2020-10-10 19:57:02</td>\n",
       "      <td>True</td>\n",
       "      <td>1486</td>\n",
       "      <td>745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.993369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1225330</td>\n",
       "      <td>NBA 2K21</td>\n",
       "      <td>75410143</td>\n",
       "      <td>english</td>\n",
       "      <td>There is very little difference from 2k20. The...</td>\n",
       "      <td>2020-09-04 06:20:35</td>\n",
       "      <td>2020-09-04 06:20:35</td>\n",
       "      <td>False</td>\n",
       "      <td>1484</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.043133</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.036822</td>\n",
       "      <td>0.029876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105600</td>\n",
       "      <td>Terraria</td>\n",
       "      <td>78393147</td>\n",
       "      <td>english</td>\n",
       "      <td>---{Graphics}---\n",
       "✖ Masterpiece\n",
       "✖ Beautiful\n",
       "✅Go...</td>\n",
       "      <td>2020-10-30 12:14:22</td>\n",
       "      <td>2020-11-26 04:01:45</td>\n",
       "      <td>True</td>\n",
       "      <td>1461</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.699785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id          app_name  review_id language  \\\n",
       "0   620980        Beat Saber   79244667  english   \n",
       "1  1113000  Persona 4 Golden   70806847  english   \n",
       "2  1145360             Hades   75662801  english   \n",
       "3  1225330          NBA 2K21   75410143  english   \n",
       "4   105600          Terraria   78393147  english   \n",
       "\n",
       "                                              review   timestamp_created  \\\n",
       "0  Since I am 80 + years old, it is very importan... 2020-11-14 10:51:22   \n",
       "1  Please buy this game if you want more Persona ... 2020-06-15 02:03:47   \n",
       "2  You can date the medusa head.\n",
       "\n",
       "Post Launch Edi... 2020-09-08 19:18:50   \n",
       "3  There is very little difference from 2k20. The... 2020-09-04 06:20:35   \n",
       "4  ---{Graphics}---\n",
       "✖ Masterpiece\n",
       "✖ Beautiful\n",
       "✅Go... 2020-10-30 12:14:22   \n",
       "\n",
       "    timestamp_updated  recommended  votes_helpful  votes_funny  ...      love  \\\n",
       "0 2020-11-14 10:51:22         True           1493          176  ...  0.001054   \n",
       "1 2020-11-26 04:15:44         True           1490           31  ...  0.000184   \n",
       "2 2020-10-10 19:57:02         True           1486          745  ...  0.000248   \n",
       "3 2020-09-04 06:20:35        False           1484           99  ...  0.000521   \n",
       "4 2020-11-26 04:01:45         True           1461          156  ...  0.001600   \n",
       "\n",
       "   nervousness  optimism     pride  realization    relief   remorse   sadness  \\\n",
       "0     0.001134  0.094612  0.003521     0.010920  0.002340  0.000460  0.001183   \n",
       "1     0.000016  0.000899  0.000021     0.000102  0.000093  0.000066  0.000069   \n",
       "2     0.000012  0.000412  0.000016     0.000564  0.000023  0.000019  0.000050   \n",
       "3     0.007182  0.003316  0.001158     0.043133  0.002145  0.000302  0.004193   \n",
       "4     0.000301  0.013872  0.000554     0.005503  0.000414  0.000160  0.000862   \n",
       "\n",
       "   surprise   neutral  \n",
       "0  0.001294  0.349538  \n",
       "1  0.000032  0.000344  \n",
       "2  0.000031  0.993369  \n",
       "3  0.036822  0.029876  \n",
       "4  0.000123  0.699785  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben uns hier für einfache Standardwerte vom Model entschieden, jedoch einmal mit der vector_size und zwischen Skip Gram und CBOW gewechselt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für Tokenisierung\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Alles entfernen was keine Buchstaben sind.\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenisierung\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Spalte\n",
    "df['cleaned_review_sv'] = df['cleaned_review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = df['cleaned_review_sv'].tolist() # Zur Liste machen für die Funktion Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip Gram | dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector_size und window sind Standard, min_count wurde auf 1 gesetzt und die Worker hoch für schnelleres berechnen. sg = 1 bedeute Skip Gram Modell.\n",
    "w2v_model = Word2Vec(sentences = tokenized_reviews, vector_size = 100, window = 5, min_count = 1, workers = 12, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion welches jeden tokenized Textreview in eine Zeile averaged, damit dies von den Modellen gelesen werden kann. Falls der Token im W2V nicht vorkommt werden dementsprechened nuller drangehängt\n",
    "def get_average_word2vec(tokens_list, model):\n",
    "    vectors = [model.wv[word] for word in tokens_list if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion angewandt bei der der Column \"cleaned_review_sv\" die tokens der Lambdafunction sind \n",
    "df['review_vector'] = df['cleaned_review_sv'].apply(lambda tokens: get_average_word2vec(tokens, w2v_model))\n",
    "\n",
    "\n",
    "word2vec_df= pd.DataFrame(df['review_vector'].tolist())\n",
    "word2vec_df.to_parquet(\"data\\\\word2vec_data\\\\word2vec_review_vector_SG_100.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip Gram | dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wie oben nur andere vector_size\n",
    "w2v_model_sg = Word2Vec(sentences = tokenized_reviews, vector_size = 300, window = 5, min_count = 1, workers = 12, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, model):\n",
    "    vectors = [model.wv[word] for word in tokens_list if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_vector_sg'] = df['cleaned_review_sv'].apply(lambda tokens: get_average_word2vec(tokens, w2v_model_sg))\n",
    "\n",
    "word2vec_df_sg = pd.DataFrame(df['review_vector_sg'].tolist())\n",
    "word2vec_df_sg.to_parquet(\"data\\\\word2vec_data\\\\word2vec_review_vector_SG_300.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW | dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wie oben nur mit sg = 0 für CBOW\n",
    "w2v_model_cbow = Word2Vec(sentences = tokenized_reviews, vector_size = 300, window = 5, min_count = 1, workers = 12, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, model):\n",
    "    vectors = [model.wv[word] for word in tokens_list if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)\n",
    "\n",
    "df['review_vector_cbow'] = df['cleaned_review_sv'].apply(lambda tokens: get_average_word2vec(tokens, w2v_model_cbow))\n",
    "\n",
    "word2vec_df_cbow = pd.DataFrame(df['review_vector_cbow'].tolist())\n",
    "word2vec_df_cbow.to_parquet(\"data\\\\word2vec_data\\\\word2vec_review_vector_CBOW_300.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_id</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>timestamp_created</th>\n",
       "      <th>timestamp_updated</th>\n",
       "      <th>recommended</th>\n",
       "      <th>votes_helpful</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>...</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>cleaned_review_sv</th>\n",
       "      <th>review_vector</th>\n",
       "      <th>review_vector_sg</th>\n",
       "      <th>review_vector_cbow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620980</td>\n",
       "      <td>Beat Saber</td>\n",
       "      <td>79244667</td>\n",
       "      <td>english</td>\n",
       "      <td>Since I am 80 + years old, it is very importan...</td>\n",
       "      <td>2020-11-14 10:51:22</td>\n",
       "      <td>2020-11-14 10:51:22</td>\n",
       "      <td>True</td>\n",
       "      <td>1493</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.349538</td>\n",
       "      <td>[since, i, am, years, old, it, is, very, impor...</td>\n",
       "      <td>[-0.2726916, 0.19899613, 0.22751918, 0.1773474...</td>\n",
       "      <td>[-0.081652, 0.052123804, -0.22066393, -0.18838...</td>\n",
       "      <td>[-0.43056703, -0.7118685, -0.4633068, 0.205449...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1113000</td>\n",
       "      <td>Persona 4 Golden</td>\n",
       "      <td>70806847</td>\n",
       "      <td>english</td>\n",
       "      <td>Please buy this game if you want more Persona ...</td>\n",
       "      <td>2020-06-15 02:03:47</td>\n",
       "      <td>2020-11-26 04:15:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1490</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>[please, buy, this, game, if, you, want, more,...</td>\n",
       "      <td>[-0.2883354, 0.14829771, 0.15931796, 0.2871740...</td>\n",
       "      <td>[-0.082975045, 0.08470067, -0.20024474, -0.164...</td>\n",
       "      <td>[0.0012572557, -0.55559087, -0.65425366, 0.860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1145360</td>\n",
       "      <td>Hades</td>\n",
       "      <td>75662801</td>\n",
       "      <td>english</td>\n",
       "      <td>You can date the medusa head.\n",
       "\n",
       "Post Launch Edi...</td>\n",
       "      <td>2020-09-08 19:18:50</td>\n",
       "      <td>2020-10-10 19:57:02</td>\n",
       "      <td>True</td>\n",
       "      <td>1486</td>\n",
       "      <td>745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.993369</td>\n",
       "      <td>[you, can, date, the, medusa, head, post, laun...</td>\n",
       "      <td>[-0.39996672, 0.18868315, 0.123849116, 0.31465...</td>\n",
       "      <td>[-0.086352706, 0.16583632, -0.22587965, -0.156...</td>\n",
       "      <td>[-0.27830422, -0.15577766, -0.24705377, 0.0147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1225330</td>\n",
       "      <td>NBA 2K21</td>\n",
       "      <td>75410143</td>\n",
       "      <td>english</td>\n",
       "      <td>There is very little difference from 2k20. The...</td>\n",
       "      <td>2020-09-04 06:20:35</td>\n",
       "      <td>2020-09-04 06:20:35</td>\n",
       "      <td>False</td>\n",
       "      <td>1484</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043133</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.036822</td>\n",
       "      <td>0.029876</td>\n",
       "      <td>[there, is, very, little, difference, from, k,...</td>\n",
       "      <td>[-0.25944784, 0.16957393, 0.18401708, 0.324794...</td>\n",
       "      <td>[-0.042988148, 0.15374173, -0.17773253, -0.180...</td>\n",
       "      <td>[-0.34721655, -0.48042405, -0.2059811, -0.0819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105600</td>\n",
       "      <td>Terraria</td>\n",
       "      <td>78393147</td>\n",
       "      <td>english</td>\n",
       "      <td>---{Graphics}---\n",
       "✖ Masterpiece\n",
       "✖ Beautiful\n",
       "✅Go...</td>\n",
       "      <td>2020-10-30 12:14:22</td>\n",
       "      <td>2020-11-26 04:01:45</td>\n",
       "      <td>True</td>\n",
       "      <td>1461</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.699785</td>\n",
       "      <td>[graphics, masterpiece, beautiful, good, decen...</td>\n",
       "      <td>[-0.31568402, 0.09190998, 0.23750567, 0.391256...</td>\n",
       "      <td>[0.032259822, 0.15602392, -0.17051366, -0.1357...</td>\n",
       "      <td>[-0.033696365, -0.47074488, -0.41680184, 0.202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id          app_name  review_id language  \\\n",
       "0   620980        Beat Saber   79244667  english   \n",
       "1  1113000  Persona 4 Golden   70806847  english   \n",
       "2  1145360             Hades   75662801  english   \n",
       "3  1225330          NBA 2K21   75410143  english   \n",
       "4   105600          Terraria   78393147  english   \n",
       "\n",
       "                                              review   timestamp_created  \\\n",
       "0  Since I am 80 + years old, it is very importan... 2020-11-14 10:51:22   \n",
       "1  Please buy this game if you want more Persona ... 2020-06-15 02:03:47   \n",
       "2  You can date the medusa head.\n",
       "\n",
       "Post Launch Edi... 2020-09-08 19:18:50   \n",
       "3  There is very little difference from 2k20. The... 2020-09-04 06:20:35   \n",
       "4  ---{Graphics}---\n",
       "✖ Masterpiece\n",
       "✖ Beautiful\n",
       "✅Go... 2020-10-30 12:14:22   \n",
       "\n",
       "    timestamp_updated  recommended  votes_helpful  votes_funny  ...  \\\n",
       "0 2020-11-14 10:51:22         True           1493          176  ...   \n",
       "1 2020-11-26 04:15:44         True           1490           31  ...   \n",
       "2 2020-10-10 19:57:02         True           1486          745  ...   \n",
       "3 2020-09-04 06:20:35        False           1484           99  ...   \n",
       "4 2020-11-26 04:01:45         True           1461          156  ...   \n",
       "\n",
       "   realization    relief   remorse   sadness  surprise   neutral  \\\n",
       "0     0.010920  0.002340  0.000460  0.001183  0.001294  0.349538   \n",
       "1     0.000102  0.000093  0.000066  0.000069  0.000032  0.000344   \n",
       "2     0.000564  0.000023  0.000019  0.000050  0.000031  0.993369   \n",
       "3     0.043133  0.002145  0.000302  0.004193  0.036822  0.029876   \n",
       "4     0.005503  0.000414  0.000160  0.000862  0.000123  0.699785   \n",
       "\n",
       "                                   cleaned_review_sv  \\\n",
       "0  [since, i, am, years, old, it, is, very, impor...   \n",
       "1  [please, buy, this, game, if, you, want, more,...   \n",
       "2  [you, can, date, the, medusa, head, post, laun...   \n",
       "3  [there, is, very, little, difference, from, k,...   \n",
       "4  [graphics, masterpiece, beautiful, good, decen...   \n",
       "\n",
       "                                       review_vector  \\\n",
       "0  [-0.2726916, 0.19899613, 0.22751918, 0.1773474...   \n",
       "1  [-0.2883354, 0.14829771, 0.15931796, 0.2871740...   \n",
       "2  [-0.39996672, 0.18868315, 0.123849116, 0.31465...   \n",
       "3  [-0.25944784, 0.16957393, 0.18401708, 0.324794...   \n",
       "4  [-0.31568402, 0.09190998, 0.23750567, 0.391256...   \n",
       "\n",
       "                                    review_vector_sg  \\\n",
       "0  [-0.081652, 0.052123804, -0.22066393, -0.18838...   \n",
       "1  [-0.082975045, 0.08470067, -0.20024474, -0.164...   \n",
       "2  [-0.086352706, 0.16583632, -0.22587965, -0.156...   \n",
       "3  [-0.042988148, 0.15374173, -0.17773253, -0.180...   \n",
       "4  [0.032259822, 0.15602392, -0.17051366, -0.1357...   \n",
       "\n",
       "                                  review_vector_cbow  \n",
       "0  [-0.43056703, -0.7118685, -0.4633068, 0.205449...  \n",
       "1  [0.0012572557, -0.55559087, -0.65425366, 0.860...  \n",
       "2  [-0.27830422, -0.15577766, -0.24705377, 0.0147...  \n",
       "3  [-0.34721655, -0.48042405, -0.2059811, -0.0819...  \n",
       "4  [-0.033696365, -0.47074488, -0.41680184, 0.202...  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit Emotionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CBOW | dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = pd.concat([df[[\"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "            \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "            \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
    "            \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
    "           \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"]], word2vec_df_cbow], axis = 1)\n",
    "\n",
    "# Als String machen, da es sonst Probleme gibt für die train_test_split Funktion\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "y = df['recommended']\n",
    "\n",
    "# random_state sagt den seed, test_size ist 20% und stratify = y behält das Verhältnis der recommended Spalte, was gut für imbalanced data ist (was hier der Fall ist)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.61      0.68     15830\n",
      "        True       0.90      0.95      0.92     55832\n",
      "\n",
      "    accuracy                           0.87     71662\n",
      "   macro avg       0.83      0.78      0.80     71662\n",
      "weighted avg       0.87      0.87      0.87     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wieder einen Seed setzen, 10 iterationen und alle vorhandened CPU threads benutzen und das Model erstellen\n",
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 10, n_jobs = -1)\n",
    "\n",
    "# Das Modell auf trainieren mit den Trainingsdaten\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Das Modell auf die Testdaten vorhersagen\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "# classification_report() Funktion benutzen um alle Metriken dazu bekommen, zero_division = 0, wenn es eine Division mit 0 gibt wird das Ergebnis 0. \n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weight = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.86      0.74     15830\n",
      "        True       0.96      0.87      0.91     55832\n",
      "\n",
      "    accuracy                           0.87     71662\n",
      "   macro avg       0.80      0.86      0.83     71662\n",
      "weighted avg       0.89      0.87      0.87     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Für alle das selbe, nur diesmal wird ein class_weight auf 'balanced' gesetzt was dafür sorgt, dass die unterrepräsentierte Klasse (recommended: False) mehr Gewicht bekommt.\n",
    "logreg_model = LogisticRegression(class_weight='balanced', random_state = 42, max_iter = 10, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.72      0.76     15830\n",
      "        True       0.92      0.95      0.94     55832\n",
      "\n",
      "    accuracy                           0.90     71662\n",
      "   macro avg       0.87      0.84      0.85     71662\n",
      "weighted avg       0.90      0.90      0.90     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weight = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.86      0.76     15830\n",
      "        True       0.96      0.88      0.92     55832\n",
      "\n",
      "    accuracy                           0.88     71662\n",
      "   macro avg       0.81      0.87      0.84     71662\n",
      "weighted avg       0.89      0.88      0.88     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(class_weight='balanced', random_state = 42, max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max iterations = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.72      0.76     15830\n",
      "        True       0.92      0.95      0.94     55832\n",
      "\n",
      "    accuracy                           0.90     71662\n",
      "   macro avg       0.87      0.84      0.85     71662\n",
      "weighted avg       0.90      0.90      0.90     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 1000, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weight = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.86      0.75     15830\n",
      "        True       0.96      0.88      0.92     55832\n",
      "\n",
      "    accuracy                           0.88     71662\n",
      "   macro avg       0.81      0.87      0.84     71662\n",
      "weighted avg       0.89      0.88      0.88     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(class_weight='balanced', random_state = 42, max_iter = 1000, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip Gram | dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df[[\"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "            \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "            \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
    "            \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
    "           \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"]], word2vec_df_sg], axis = 1)\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "y = df['recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.63      0.71     15830\n",
      "        True       0.90      0.95      0.93     55832\n",
      "\n",
      "    accuracy                           0.88     71662\n",
      "   macro avg       0.85      0.79      0.82     71662\n",
      "weighted avg       0.88      0.88      0.88     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 10, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weight = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.86      0.72     15830\n",
      "        True       0.95      0.85      0.90     55832\n",
      "\n",
      "    accuracy                           0.85     71662\n",
      "   macro avg       0.79      0.86      0.81     71662\n",
      "weighted avg       0.88      0.85      0.86     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(class_weight='balanced', random_state = 42, max_iter = 10, n_jobs = -1)\n",
    "a\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.73      0.77     15830\n",
      "        True       0.92      0.95      0.94     55832\n",
      "\n",
      "    accuracy                           0.90     71662\n",
      "   macro avg       0.87      0.84      0.85     71662\n",
      "weighted avg       0.90      0.90      0.90     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weight = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.87      0.76     15830\n",
      "        True       0.96      0.88      0.92     55832\n",
      "\n",
      "    accuracy                           0.88     71662\n",
      "   macro avg       0.82      0.88      0.84     71662\n",
      "weighted avg       0.90      0.88      0.89     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(class_weight='balanced', random_state = 42, max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip Gram | dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df[[\"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "            \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "            \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
    "            \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
    "           \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"]], word2vec_df], axis = 1)\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "y = df['recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.64      0.71     15830\n",
      "        True       0.90      0.96      0.93     55832\n",
      "\n",
      "    accuracy                           0.89     71662\n",
      "   macro avg       0.85      0.80      0.82     71662\n",
      "weighted avg       0.88      0.89      0.88     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 10, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weight = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.86      0.72     15830\n",
      "        True       0.95      0.85      0.90     55832\n",
      "\n",
      "    accuracy                           0.85     71662\n",
      "   macro avg       0.79      0.85      0.81     71662\n",
      "weighted avg       0.88      0.85      0.86     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(class_weight='balanced', random_state = 42, max_iter = 10, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max iteration = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.72      0.76     15830\n",
      "        True       0.92      0.95      0.94     55832\n",
      "\n",
      "    accuracy                           0.90     71662\n",
      "   macro avg       0.87      0.83      0.85     71662\n",
      "weighted avg       0.90      0.90      0.90     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weight = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.86      0.75     15830\n",
      "        True       0.96      0.88      0.92     55832\n",
      "\n",
      "    accuracy                           0.88     71662\n",
      "   macro avg       0.81      0.87      0.84     71662\n",
      "weighted avg       0.89      0.88      0.88     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(class_weight='balanced', random_state = 42, max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Logistische Regression scheint es besser zu sein, class_weight = 'balanced' wegzulassen. Das 300er skip gram modell hat am besten abgeschnitten bzgl der Metriken und 100 iterationen scheinen auch zu reichen. Daher werden wir nur mehr das 300er skip gram Modell für den Random Forest benutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip Gram | dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number estimators = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df[[\"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "            \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "            \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
    "            \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
    "           \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"]], word2vec_df_sg], axis = 1)\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "y = df['recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.73      0.75     15830\n",
      "        True       0.92      0.94      0.93     55832\n",
      "\n",
      "    accuracy                           0.89     71662\n",
      "   macro avg       0.85      0.83      0.84     71662\n",
      "weighted avg       0.89      0.89      0.89     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Einziger Unterschied ist nun, dass wir n_estimators haben welche die Anzahl der Bäume angeben\n",
    "rf_model = RandomForestClassifier(n_estimators = 10, random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weights = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.68      0.74     15830\n",
      "        True       0.91      0.95      0.93     55832\n",
      "\n",
      "    accuracy                           0.89     71662\n",
      "   macro avg       0.86      0.82      0.84     71662\n",
      "weighted avg       0.89      0.89      0.89     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 10, class_weight = 'balanced', random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number estimators = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No class weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.70      0.77     15830\n",
      "        True       0.92      0.96      0.94     55832\n",
      "\n",
      "    accuracy                           0.91     71662\n",
      "   macro avg       0.88      0.83      0.86     71662\n",
      "weighted avg       0.90      0.91      0.90     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100, random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class weights = 'balanced'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.66      0.74     15830\n",
      "        True       0.91      0.97      0.94     55832\n",
      "\n",
      "    accuracy                           0.90     71662\n",
      "   macro avg       0.88      0.81      0.84     71662\n",
      "weighted avg       0.90      0.90      0.90     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100, class_weight = 'balanced', random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier schneidet das Modell ohne balanced class weights besser ab, wenn auch nicht um sehr viel. Die n_estimators von 10 auf 100 hochzuschrauben hat for allem die Precision der \"not recommended\" Daten verbessert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Außerderm hat die Random Forest Modell besser als die einfache logistische Regression abgeschnitten. Eine accuracy Verbesserung um 0.01, sowie von Precision und F1-Score um auch 0.01. Nur Der Recall hat sich leicht verschlechtert um 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ohne Emotionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die besten logistic regression und random forest Modelle werden nun ohne Emotionen getestet für den Unterschied zu den vorherigen Modellen, mit und ohne class_weights = 'balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist X nur der Word2Vec vector des 300er Skip Gram Modells.\n",
    "X = word2vec_df_sg\n",
    "y = df['recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.48      0.62     15848\n",
      "        True       0.87      0.98      0.92     55814\n",
      "\n",
      "    accuracy                           0.87     71662\n",
      "   macro avg       0.87      0.73      0.77     71662\n",
      "weighted avg       0.87      0.87      0.86     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100, random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.63      0.70     15848\n",
      "        True       0.90      0.95      0.93     55814\n",
      "\n",
      "    accuracy                           0.88     71662\n",
      "   macro avg       0.84      0.79      0.81     71662\n",
      "weighted avg       0.88      0.88      0.88     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class weights = 'balanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.44      0.58     15848\n",
      "        True       0.86      0.98      0.92     55814\n",
      "\n",
      "    accuracy                           0.86     71662\n",
      "   macro avg       0.86      0.71      0.75     71662\n",
      "weighted avg       0.86      0.86      0.84     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100, class_weight = 'balanced', random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.86      0.72     15848\n",
      "        True       0.96      0.85      0.90     55814\n",
      "\n",
      "    accuracy                           0.85     71662\n",
      "   macro avg       0.79      0.86      0.81     71662\n",
      "weighted avg       0.88      0.85      0.86     71662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state = 42, class_weight = 'balanced', max_iter = 100, n_jobs = -1)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man erkennt, dass ohne die Emotionen die \"Not Recommended\" Spalte schlechter abschneidet als mit. Die Diskrepanz zwischen der Precision und dem Recall sind hier vor allem stärker zu sehen. Das balancing hat hier auch einen größeren Einfluss, was an den umgekerten Precision und Recall Werten bei jeweils der Logistischen Regression und dem Random Forest zu sehen ist.\n",
    "\n",
    "Dennoch sind die Modelle mit den Emotionen besser was die Metrikwerte angeht als ohne.\n",
    "\n",
    "Auch ohne das Emotionsmodell im Vorhinein, werden die Reviews gut klassifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Vergleich zu dem DistilBert Modell Auch die supervised Modelle scheinen nicht viel schlechter abzuschneiden was die Klassifikation der Reviews angeht. Es schwankt zwischen 0.05 - 0.07 je Metrik. Mit einer Accuracy von 0.9 ist es dennoch ein überraschend gutes Ergebnis, vor allem wenn man die geringere Trainingszeit dagegenrechnet. Womöglich kann man mit einem erweiterten Grid Search die Metrik-Werte von den supervised Modellen noch verbessern, da sich dieses Projekt jedoch um ein Transformer-Modell handelt, belassen wir es bei diesen Ergebnissen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
